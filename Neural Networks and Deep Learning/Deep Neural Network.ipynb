{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for Image Classification: Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from skimage import transform\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans Mono'\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = h5py.File('./datasets/test_catvnoncat.h5', 'r')\n",
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    test_data = h5py.File('./datasets/test_catvnoncat.h5', 'r')\n",
    "    test_set_x =  np.array(test_data['test_set_x'][:])\n",
    "    test_set_y =  np.array(test_data['test_set_y'][:])\n",
    "#     test_set_y = test_set_y.reshape((-1, 1))\n",
    "\n",
    "    train_data = h5py.File('./datasets/train_catvnoncat.h5', 'r')\n",
    "    train_set_x =  np.array(train_data['train_set_x'][:])\n",
    "    train_set_y =  np.array(train_data['train_set_y'][:])\n",
    "#     train_set_y = train_set_y.reshape((-1, 1))\n",
    "    \n",
    "    labels = np.array(train_data['list_classes'][:])\n",
    "    \n",
    "    return train_set_x, train_set_y, test_set_x, test_set_y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y, test_set_x, test_set_y, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 10\n",
    "plt.imshow(train_set_x[index]/255. + np.random.randn(64, 64, 3) * 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_set_x.shape[0]\n",
    "X_train, y_train = train_set_x.reshape((m, -1)) / 255., train_set_y\n",
    "m = test_set_x.shape[0]\n",
    "X_test, y_test = test_set_x.reshape((m, -1)) / 255., test_set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for x in X_train:\n",
    "    l.append(x + np.random.randn(12288) * 0.02)\n",
    "l = np.array(l)\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, l), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.tile(y_train, (2, ))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train x: ', X_train.shape)\n",
    "print('train y: ', y_train.shape)\n",
    "\n",
    "print('test x: ', X_test.shape)\n",
    "print('test y: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_input_dims, n_neurons, activation=None, weights=None, bias=None):\n",
    "        self.weights = weights if weights is not None else np.random.randn(\n",
    "            n_input_dims, n_neurons) * np.sqrt(1 / n_neurons)\n",
    "        self.bias = bias if bias is not None else np.random.randn(n_neurons) * 0.1\n",
    "        self.activation = activation\n",
    "        self.A = None\n",
    "        self.dA = None\n",
    "        self.dZ = None\n",
    "\n",
    "    def activate(self, X):\n",
    "        Z = np.dot(X, self.weights) + self.bias\n",
    "        # 激活函数的输出\n",
    "        self.A = self._apply_activation(Z)\n",
    "        return self.A\n",
    "    \n",
    "    def _apply_activation(self, Z):\n",
    "        # 激活函数\n",
    "        if self.activation is None:\n",
    "            return Z\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, Z)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-Z))\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(Z)\n",
    "        else:\n",
    "            return Z\n",
    "    \n",
    "    def derivative(self, A):\n",
    "        # 激活函数的导数\n",
    "        if self.activation is None:\n",
    "            return np.ones_like(A)\n",
    "        elif self.activation == 'relu':\n",
    "            # return np.where(A <= 0, 0., 1.)\n",
    "            d = np.array(A, copy=True)\n",
    "            d[A <= 0] = 0.\n",
    "            d[A > 0] = 1.\n",
    "            return d \n",
    "        elif self.activation == 'sigmoid':\n",
    "            return A  * (1 - A)\n",
    "        elif self.activation == 'tanh':\n",
    "            return 1 - A ** 2\n",
    "        else:\n",
    "            return A\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"weigths: {self.weights.shape}\\n bias: {self.bias.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAR_0 = 1e-10\n",
    "class DeepNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.activate(X)\n",
    "        return X\n",
    "\n",
    "    def loss(self, y_true, y_preds):\n",
    "        # 交叉熵误差\n",
    "        assert(y_true.shape == y_preds.shape)\n",
    "        loss_ = - y_true* np.log(y_preds + NEAR_0) - (1 - y_true)*np.log(1 - y_preds + NEAR_0)  \n",
    "\n",
    "        return np.squeeze(np.mean(loss_, axis=0))\n",
    "    \n",
    "    def backpropagation(self, X, y, learning_rate):\n",
    "        # 反向传播算法 计算每一层的delta \n",
    "        # 前向计算 得到输出值\n",
    "        m = X.shape[0]  # batch size\n",
    "        out = self.feed_forward(X)  # (m, 1)\n",
    "        # print(out.shape)\n",
    "        # loss_ = self.loss(y, out)\n",
    "\n",
    "        for i in reversed(range(len(self.layers))):  # 从最后一层开始\n",
    "            layer = self.layers[i]\n",
    "            if layer == self.layers[-1]:  # 输出层\n",
    "                # 使用 交叉熵 误差\n",
    "                assert(y.shape == out.shape)\n",
    "                layer.dA = -y/(out + NEAR_0) + (1-y) / (1-out + NEAR_0)\n",
    "                # layer.dA = -y / out + (1-y)/(1-out)  # dL/dA^K  # (m, 1)\n",
    "                layer.dZ = layer.dA * layer.derivative(out) # dL/dZ^K  (m, 1) (m, 1)\n",
    "            else:  # 隐藏层\n",
    "                next_layer = self.layers[i + 1]\n",
    "                layer.dA = next_layer.dZ @ next_layer.weights.T  # dL/dA^J (m, 1) (1, k)\n",
    "                # dL/dZ^J (m, k) (m,k)\n",
    "                layer.dZ = layer.dA * layer.derivative(layer.A)\n",
    "        \n",
    "        # 更新参数\n",
    "        for i in range(len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            # 上一层的输出 本层的输入\n",
    "            o_i = X if i == 0 else self.layers[i-1].A\n",
    "            # weights (I, J)\n",
    "            # o_i (m, I)\n",
    "            # dZ (m, J)\n",
    "            layer.weights -= learning_rate *  o_i.T @ layer.dZ * 1 / m # (I, J)\n",
    "            layer.bias -=  learning_rate * np.sum(layer.dZ) * 1 / m # (J, )\n",
    "\n",
    "    def train(self, X, y, X_test, y_test, learning_rate=0.01 ,max_epochs=300, batch_size=32):\n",
    "        y = y.reshape(-1, 1)\n",
    "        cross_entropy = []\n",
    "        accuracy = []\n",
    "        split_size = X.shape[0] // batch_size\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            for x, y_true in zip(np.array_split(X, split_size), np.array_split(y, split_size)):\n",
    "                self.backpropagation(x, y_true, learning_rate)\n",
    "            # self.backpropagation(X, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                # mse = np.mean(np.square(self.feed_forward(X) - y_onehot))\n",
    "                loss = self.loss(y, self.feed_forward(X))\n",
    "                cross_entropy.append(loss)\n",
    "                \n",
    "                predict = self.predict(X_train)\n",
    "                train_acc = np.sum(y_train.ravel()==predict) / len(predict)\n",
    "                \n",
    "                predict = self.predict(X_test)\n",
    "                acc = np.sum(y_test.ravel()==predict) / len(predict)\n",
    "                accuracy.append(acc)\n",
    "                print(f'Epoch: {epoch}, cross_entropy: {loss}, train acc: {train_acc}, test acc: {acc}')\n",
    "        return cross_entropy, accuracy\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.feed_forward(X)\n",
    "        y_pred = np.where(y_pred >=0.5, 1, 0)\n",
    "        # out = np.argmax(y_pred, axis=1)\n",
    "        return np.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepNeuralNetwork()\n",
    "model.add_layer(Layer(X_train.shape[1], 64, 'relu'))  # h1  \n",
    "model.add_layer(Layer(64, 16, 'relu'))  # output\n",
    "model.add_layer(Layer(16, 4, 'relu'))  # output\n",
    "model.add_layer(Layer(4, 1, 'sigmoid'))  # output\n",
    "cross_entropy, accuracy = model.train(X_train, y_train, X_test, y_test, learning_rate=0.008, max_epochs=1500, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-2].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "np.sum(y_pred == y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "np.sum(y_pred == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassification(test_set_x, y_pred, y_test):\n",
    "    mis = test_set_x[y_test != y_pred]\n",
    "    for image in mis:\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.imshow(image / 255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, losses, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(X, y):\n",
    "    X = tf.cast(X, dtype=tf.float32) / 255.\n",
    "    X = tf.reshape(X, (-1, 64*64*3))\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((train_set_x, train_set_y))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((test_set_x, test_set_y))\n",
    "train_db = train_db.shuffle(1000).batch(64).map(process)\n",
    "test_db = test_db.shuffle(1000).batch(64).map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential([\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(lambda_)),\n",
    "#     layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(lambda_)), \n",
    "#     layers.Dense(4, activation='relu', kernel_regularizer=regularizers.l2(lambda_)), \n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = network.fit(train_db, epochs=150, validation_data=test_db, validation_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = network.predict_classes(X_test)\n",
    "np.sum(np.squeeze(y_pred) == np.squeeze(y_test)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassification(test_set_x, y_pred.ravel(), y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
